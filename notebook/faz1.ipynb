{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5926c8b4-589e-4db4-91b1-1163dcfd43c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faz 1 tamam: baseline çıktıları yazıldı.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# 0) Ayarlar\n",
    "# =========================\n",
    "DATA_DIR = Path(\"data/raw\")          # kendi klasörüne göre değiştir\n",
    "OUT_DIR  = Path(\"data/processed\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GPS_FILE = \"all_merged_data.csv\"   # sende tam dosya adı neyse onu yaz\n",
    "\n",
    "# Bu aralık: 19-25 Aralık (dahil)\n",
    "DATE_START = pd.Timestamp(\"2025-12-19\")\n",
    "DATE_END   = pd.Timestamp(\"2025-12-25\")\n",
    "\n",
    "# GPS örnekleme aralığı ~10 sn denmiş; ama bazen gap olabilir.\n",
    "# Mahalle süresi hesabında aşırı boşlukları şişirmemek için dt'yi bu üst limite kırpıyoruz.\n",
    "DT_CAP_SECONDS = 300  # 5 dk\n",
    "\n",
    "# Chunk okuma\n",
    "CHUNK_SIZE = 200_000\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Yardımcı Fonksiyonlar\n",
    "# =========================\n",
    "def parse_hms_to_seconds(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    'HH:MM:SS' veya benzeri formatları saniyeye çevirir.\n",
    "    Bozuk/boş değerleri 0 yapar.\n",
    "    \"\"\"\n",
    "    # pandas to_timedelta toleranslıdır; NaT -> NaN\n",
    "    td = pd.to_timedelta(series, errors=\"coerce\")\n",
    "    return td.dt.total_seconds().fillna(0).astype(np.float64)\n",
    "\n",
    "def parse_date_time(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tarih + Saat -> datetime, ayrıca date alanı üretir.\n",
    "    Tarih formatı veri setinde '19.12.2025' gibi görünüyor.\n",
    "    \"\"\"\n",
    "    # Tarih ve Saat kolonlarını stringe çevirip birleştiriyoruz\n",
    "    # dayfirst=True önemli (19.12.2025)\n",
    "    dt = pd.to_datetime(\n",
    "        df[\"Tarih\"].astype(str).str.strip() + \" \" + df[\"Saat\"].astype(str).str.strip(),\n",
    "        errors=\"coerce\",\n",
    "        dayfirst=True\n",
    "    )\n",
    "    df[\"datetime\"] = dt\n",
    "    df[\"date\"] = dt.dt.floor(\"D\")\n",
    "    return df\n",
    "\n",
    "def in_range(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    19-25 Aralık dahil filtre.\n",
    "    \"\"\"\n",
    "    mask = (df[\"date\"] >= DATE_START) & (df[\"date\"] <= DATE_END)\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "def normalize_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    vehicle_id stringe çevir, trimle.\n",
    "    \"\"\"\n",
    "    df[\"vehicle_id\"] = df[\"vehicle_id\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Chunk Bazlı Baseline Toplama\n",
    "# =========================\n",
    "vehicle_daily_rows = []     # her chunk'tan günlük araç özetleri\n",
    "# Mahalle süre hesabı için daha ince bilgi gerekiyor; onu ayrı toplayacağız\n",
    "# (Araç-gün-mahalle sürelerini hesaplamak için segment yaklaşımı: dt)\n",
    "veh_day_neigh_rows = []\n",
    "\n",
    "# Mahalle blok (visit count) için araç-gün içerisinde sıralı geçiş gerekir.\n",
    "# Chunklar araç-gün bazında parçalanabileceği için daha güvenli yaklaşım:\n",
    "#   - önce \"araç-gün\" bazında mahalle sürelerini dt ile topluyoruz (yakın doğru)\n",
    "#   - visit_count'u ikinci geçişte sadece küçük subset için hesaplayabiliriz\n",
    "# Hackathon MVP'de visit_count opsiyonel; istersen sonra ekleriz.\n",
    "#\n",
    "# Şimdilik mahalle zamanı: dt yöntemi.\n",
    "\n",
    "usecols = [\n",
    "    \"vehicle_id\",\n",
    "    \"Enlem\", \"Boylam\",\n",
    "    \"Duraklama Süresi\", \"Rölanti Süresi\",\n",
    "    \"Durum\",\n",
    "    \"Tarih\", \"Saat\",\n",
    "    \"Hız(km/sa)\",\n",
    "    \"Mesafe(km)\",\n",
    "    \"Mesafe Sayacı(km)\",\n",
    "    \"Adres\",\n",
    "    \"Mahalle\",\n",
    "    \"Kaynak\"\n",
    "]\n",
    "\n",
    "reader = pd.read_csv(\n",
    "    GPS_FILE,\n",
    "    sep=None,\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    chunksize=CHUNK_SIZE,\n",
    "    usecols=lambda c: c in usecols\n",
    ")\n",
    "\n",
    "\n",
    "for i, chunk in enumerate(reader, start=1):\n",
    "    # datetime / date\n",
    "    chunk = parse_date_time(chunk)\n",
    "    chunk = chunk.dropna(subset=[\"datetime\"])  # parse edilemeyenleri at\n",
    "    chunk = normalize_ids(chunk)\n",
    "\n",
    "    # aralık filtre\n",
    "    chunk = in_range(chunk)\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # süreleri saniyeye çevir\n",
    "    chunk[\"idle_sec\"] = parse_hms_to_seconds(chunk.get(\"Rölanti Süresi\", pd.Series(dtype=str)))\n",
    "    chunk[\"stop_sec\"] = parse_hms_to_seconds(chunk.get(\"Duraklama Süresi\", pd.Series(dtype=str)))\n",
    "\n",
    "    # mesafe kolonları\n",
    "    if \"Mesafe(km)\" in chunk.columns:\n",
    "        chunk[\"dist_km\"] = pd.to_numeric(chunk[\"Mesafe(km)\"], errors=\"coerce\").fillna(0.0)\n",
    "    else:\n",
    "        chunk[\"dist_km\"] = 0.0\n",
    "\n",
    "    if \"Mesafe Sayacı(km)\" in chunk.columns:\n",
    "        chunk[\"odo_km\"] = pd.to_numeric(chunk[\"Mesafe Sayacı(km)\"], errors=\"coerce\")\n",
    "    else:\n",
    "        chunk[\"odo_km\"] = np.nan\n",
    "\n",
    "    # ================\n",
    "    # 2A) Günlük araç metrikleri (chunk içi toplama)\n",
    "    # ================\n",
    "    g = chunk.groupby([\"date\", \"vehicle_id\"], as_index=False).agg(\n",
    "        total_dist_km=(\"dist_km\", \"sum\"),\n",
    "        total_idle_sec=(\"idle_sec\", \"sum\"),\n",
    "        total_stop_sec=(\"stop_sec\", \"sum\"),\n",
    "        first_ts=(\"datetime\", \"min\"),\n",
    "        last_ts=(\"datetime\", \"max\"),\n",
    "        # odometer varsa min-max (chunk içi) - sonra tüm chunklar birleşince tekrar min/max yapacağız\n",
    "        odo_min=(\"odo_km\", \"min\"),\n",
    "        odo_max=(\"odo_km\", \"max\"),\n",
    "        records=(\"datetime\", \"size\")\n",
    "    )\n",
    "    vehicle_daily_rows.append(g)\n",
    "\n",
    "    # ================\n",
    "    # 2B) Mahalle süresi hesabı için dt segmentleri\n",
    "    # - Her satırın dt'si bir sonraki satıra kadar geçen süre.\n",
    "    # - chunk bazında sıralama yapıyoruz; chunklar arası sınır hatası küçük olur, ama hackathon için kabul edilebilir.\n",
    "    #   (İstersen daha sonra tek pass full sort ile %100 yaparız.)\n",
    "    # ================\n",
    "    chunk = chunk.sort_values([\"vehicle_id\", \"date\", \"datetime\"])\n",
    "    # aynı vehicle_id ve date içindeki bir sonraki datetime\n",
    "    chunk[\"next_dt\"] = chunk.groupby([\"vehicle_id\", \"date\"])[\"datetime\"].shift(-1)\n",
    "    chunk[\"dt_sec\"] = (chunk[\"next_dt\"] - chunk[\"datetime\"]).dt.total_seconds()\n",
    "    chunk[\"dt_sec\"] = chunk[\"dt_sec\"].clip(lower=0, upper=DT_CAP_SECONDS).fillna(0.0)\n",
    "\n",
    "    # mahalle boşsa ayırmak için\n",
    "    chunk[\"Mahalle\"] = chunk[\"Mahalle\"].astype(str).str.strip()\n",
    "    chunk.loc[chunk[\"Mahalle\"].isin([\"\", \"nan\", \"None\"]), \"Mahalle\"] = np.nan\n",
    "\n",
    "    # araç-gün-mahalle bazında süre toplama\n",
    "    gn = chunk.dropna(subset=[\"Mahalle\"]).groupby([\"date\", \"vehicle_id\", \"Mahalle\"], as_index=False).agg(\n",
    "        time_in_neigh_sec=(\"dt_sec\", \"sum\"),\n",
    "        dist_in_neigh_km=(\"dist_km\", \"sum\"),\n",
    "        idle_in_neigh_sec=(\"idle_sec\", \"sum\"),\n",
    "        stop_in_neigh_sec=(\"stop_sec\", \"sum\"),\n",
    "        points=(\"dt_sec\", \"size\")\n",
    "    )\n",
    "    veh_day_neigh_rows.append(gn)\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Chunk işlendi: {i}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Chunk Özetlerini Birleştir & Nihai Baseline Tablolarını Üret\n",
    "# =========================\n",
    "vehicle_daily = pd.concat(vehicle_daily_rows, ignore_index=True)\n",
    "\n",
    "# Chunk içi topladığımız odo_min/max'ları tekrar araç-gün seviyesinde birleştiriyoruz\n",
    "vehicle_daily_final = vehicle_daily.groupby([\"date\", \"vehicle_id\"], as_index=False).agg(\n",
    "    total_dist_km=(\"total_dist_km\", \"sum\"),\n",
    "    total_idle_sec=(\"total_idle_sec\", \"sum\"),\n",
    "    total_stop_sec=(\"total_stop_sec\", \"sum\"),\n",
    "    first_ts=(\"first_ts\", \"min\"),\n",
    "    last_ts=(\"last_ts\", \"max\"),\n",
    "    odo_min=(\"odo_min\", \"min\"),\n",
    "    odo_max=(\"odo_max\", \"max\"),\n",
    "    records=(\"records\", \"sum\")\n",
    ")\n",
    "\n",
    "# Odometer varsa, dist_km'yi daha güvenilir hale getirmek için \"odo delta\" üretebiliriz\n",
    "vehicle_daily_final[\"odo_dist_km\"] = vehicle_daily_final[\"odo_max\"] - vehicle_daily_final[\"odo_min\"]\n",
    "\n",
    "# Eğer Mesafe(km) güvenilmezse (çok 0 vs), odometer delta'ya geçilebilir.\n",
    "# Şimdilik ikisini de raporluyoruz.\n",
    "vehicle_daily_final[\"work_duration_sec\"] = (vehicle_daily_final[\"last_ts\"] - vehicle_daily_final[\"first_ts\"]).dt.total_seconds().fillna(0)\n",
    "\n",
    "# saniyeleri daha okunur yapalım\n",
    "vehicle_daily_final[\"total_idle_hr\"] = vehicle_daily_final[\"total_idle_sec\"] / 3600\n",
    "vehicle_daily_final[\"total_stop_hr\"] = vehicle_daily_final[\"total_stop_sec\"] / 3600\n",
    "vehicle_daily_final[\"work_duration_hr\"] = vehicle_daily_final[\"work_duration_sec\"] / 3600\n",
    "\n",
    "# Kaydet\n",
    "vehicle_daily_final.to_csv(OUT_DIR / \"baseline_daily_vehicle_metrics.csv\", index=False)\n",
    "\n",
    "\n",
    "# ================\n",
    "# 3B) Mahalle metrikleri (günlük mahalle toplamları)\n",
    "# ================\n",
    "veh_day_neigh = pd.concat(veh_day_neigh_rows, ignore_index=True)\n",
    "\n",
    "# Mahalle-gün bazında tüm araçlardan birleştir\n",
    "neigh_daily_final = veh_day_neigh.groupby([\"date\", \"Mahalle\"], as_index=False).agg(\n",
    "    total_time_in_neigh_sec=(\"time_in_neigh_sec\", \"sum\"),\n",
    "    total_dist_in_neigh_km=(\"dist_in_neigh_km\", \"sum\"),\n",
    "    total_idle_in_neigh_sec=(\"idle_in_neigh_sec\", \"sum\"),\n",
    "    total_stop_in_neigh_sec=(\"stop_in_neigh_sec\", \"sum\"),\n",
    "    total_points=(\"points\", \"sum\"),\n",
    "    vehicles_served=(\"vehicle_id\", \"nunique\")\n",
    ")\n",
    "\n",
    "neigh_daily_final[\"total_time_in_neigh_hr\"] = neigh_daily_final[\"total_time_in_neigh_sec\"] / 3600\n",
    "neigh_daily_final[\"total_idle_in_neigh_hr\"] = neigh_daily_final[\"total_idle_in_neigh_sec\"] / 3600\n",
    "neigh_daily_final[\"total_stop_in_neigh_hr\"] = neigh_daily_final[\"total_stop_in_neigh_sec\"] / 3600\n",
    "\n",
    "neigh_daily_final.to_csv(OUT_DIR / \"baseline_daily_neighborhood_metrics.csv\", index=False)\n",
    "\n",
    "# Opsiyonel: araç-gün-mahalle kırılımını da kaydedelim (ileride visit_count vs için yararlı)\n",
    "veh_day_neigh.to_csv(OUT_DIR / \"baseline_vehicle_neighborhood_time.csv\", index=False)\n",
    "\n",
    "print(\"Faz 1 tamam: baseline çıktıları yazıldı.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29dc85c-c491-4e3b-9fb5-3583d095bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faz 1 tamam.\n",
      "Yazılan dosyalar:\n",
      " - C:\\Users\\sefas\\OneDrive\\Masaüstü\\NB_hackathon_2025-main\\baseline_daily_vehicle_metrics.csv\n",
      " - C:\\Users\\sefas\\OneDrive\\Masaüstü\\NB_hackathon_2025-main\\baseline_daily_neighborhood_metrics.csv\n",
      " - C:\\Users\\sefas\\OneDrive\\Masaüstü\\NB_hackathon_2025-main\\baseline_vehicle_neighborhood_time.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# 0) Ayarlar (aynı klasör)\n",
    "# =========================\n",
    "BASE_DIR = Path(\".\")  # notebook hangi klasördeyse orası\n",
    "GPS_FILE = BASE_DIR / \"all_merged_data.csv\"  # aynı klasörde\n",
    "\n",
    "# çıktı dosyaları yine aynı klasöre yazılacak\n",
    "OUT_VEHICLE = BASE_DIR / \"baseline_daily_vehicle_metrics.csv\"\n",
    "OUT_NEIGH   = BASE_DIR / \"baseline_daily_neighborhood_metrics.csv\"\n",
    "OUT_VEH_NEI = BASE_DIR / \"baseline_vehicle_neighborhood_time.csv\"\n",
    "\n",
    "# Bu aralık: 19-25 Aralık (dahil)\n",
    "DATE_START = pd.Timestamp(\"2025-12-19\")\n",
    "DATE_END   = pd.Timestamp(\"2025-12-25\")\n",
    "\n",
    "DT_CAP_SECONDS = 300   # dt üst limit (5 dk)\n",
    "CHUNK_SIZE = 200_000\n",
    "\n",
    "# =========================\n",
    "# 1) Yardımcı Fonksiyonlar\n",
    "# =========================\n",
    "def parse_hms_to_seconds(series: pd.Series) -> pd.Series:\n",
    "    td = pd.to_timedelta(series, errors=\"coerce\")\n",
    "    return td.dt.total_seconds().fillna(0).astype(np.float64)\n",
    "\n",
    "def parse_date_time(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    dt = pd.to_datetime(\n",
    "        df[\"Tarih\"].astype(str).str.strip() + \" \" + df[\"Saat\"].astype(str).str.strip(),\n",
    "        errors=\"coerce\",\n",
    "        dayfirst=True\n",
    "    )\n",
    "    df[\"datetime\"] = dt\n",
    "    df[\"date\"] = dt.dt.floor(\"D\")\n",
    "    return df\n",
    "\n",
    "def in_range(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    mask = (df[\"date\"] >= DATE_START) & (df[\"date\"] <= DATE_END)\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "def normalize_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"vehicle_id\"] = df[\"vehicle_id\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# 2) Chunk Bazlı Baseline Toplama\n",
    "# =========================\n",
    "vehicle_daily_rows = []\n",
    "veh_day_neigh_rows = []\n",
    "\n",
    "usecols = [\n",
    "    \"vehicle_id\",\n",
    "    \"Enlem\", \"Boylam\",\n",
    "    \"Duraklama Süresi\", \"Rölanti Süresi\",\n",
    "    \"Durum\",\n",
    "    \"Tarih\", \"Saat\",\n",
    "    \"Hız(km/sa)\",\n",
    "    \"Mesafe(km)\",\n",
    "    \"Mesafe Sayacı(km)\",\n",
    "    \"Adres\",\n",
    "    \"Mahalle\",\n",
    "    \"Kaynak\"\n",
    "]\n",
    "\n",
    "reader = pd.read_csv(\n",
    "    GPS_FILE,\n",
    "    sep=None,\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    chunksize=CHUNK_SIZE,\n",
    "    usecols=lambda c: c in usecols\n",
    ")\n",
    "\n",
    "for i, chunk in enumerate(reader, start=1):\n",
    "    chunk = parse_date_time(chunk)\n",
    "    chunk = chunk.dropna(subset=[\"datetime\"])\n",
    "    chunk = normalize_ids(chunk)\n",
    "\n",
    "    chunk = in_range(chunk)\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    chunk[\"idle_sec\"] = parse_hms_to_seconds(chunk.get(\"Rölanti Süresi\", pd.Series(dtype=str)))\n",
    "    chunk[\"stop_sec\"] = parse_hms_to_seconds(chunk.get(\"Duraklama Süresi\", pd.Series(dtype=str)))\n",
    "\n",
    "    chunk[\"dist_km\"] = pd.to_numeric(chunk.get(\"Mesafe(km)\", 0), errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    if \"Mesafe Sayacı(km)\" in chunk.columns:\n",
    "        chunk[\"odo_km\"] = pd.to_numeric(chunk[\"Mesafe Sayacı(km)\"], errors=\"coerce\")\n",
    "    else:\n",
    "        chunk[\"odo_km\"] = np.nan\n",
    "\n",
    "    # ---- 2A) Günlük araç metrikleri\n",
    "    g = chunk.groupby([\"date\", \"vehicle_id\"], as_index=False).agg(\n",
    "        total_dist_km=(\"dist_km\", \"sum\"),\n",
    "        total_idle_sec=(\"idle_sec\", \"sum\"),\n",
    "        total_stop_sec=(\"stop_sec\", \"sum\"),\n",
    "        first_ts=(\"datetime\", \"min\"),\n",
    "        last_ts=(\"datetime\", \"max\"),\n",
    "        odo_min=(\"odo_km\", \"min\"),\n",
    "        odo_max=(\"odo_km\", \"max\"),\n",
    "        records=(\"datetime\", \"size\")\n",
    "    )\n",
    "    vehicle_daily_rows.append(g)\n",
    "\n",
    "    # ---- 2B) Mahalle süresi (dt yaklaşımı)\n",
    "    chunk = chunk.sort_values([\"vehicle_id\", \"date\", \"datetime\"])\n",
    "    chunk[\"next_dt\"] = chunk.groupby([\"vehicle_id\", \"date\"])[\"datetime\"].shift(-1)\n",
    "    chunk[\"dt_sec\"] = (chunk[\"next_dt\"] - chunk[\"datetime\"]).dt.total_seconds()\n",
    "    chunk[\"dt_sec\"] = chunk[\"dt_sec\"].clip(lower=0, upper=DT_CAP_SECONDS).fillna(0.0)\n",
    "\n",
    "    chunk[\"Mahalle\"] = chunk[\"Mahalle\"].astype(str).str.strip()\n",
    "    chunk.loc[chunk[\"Mahalle\"].isin([\"\", \"nan\", \"None\"]), \"Mahalle\"] = np.nan\n",
    "\n",
    "    gn = chunk.dropna(subset=[\"Mahalle\"]).groupby([\"date\", \"vehicle_id\", \"Mahalle\"], as_index=False).agg(\n",
    "        time_in_neigh_sec=(\"dt_sec\", \"sum\"),\n",
    "        dist_in_neigh_km=(\"dist_km\", \"sum\"),\n",
    "        idle_in_neigh_sec=(\"idle_sec\", \"sum\"),\n",
    "        stop_in_neigh_sec=(\"stop_sec\", \"sum\"),\n",
    "        points=(\"dt_sec\", \"size\")\n",
    "    )\n",
    "    veh_day_neigh_rows.append(gn)\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"Chunk işlendi: {i}\")\n",
    "\n",
    "# =========================\n",
    "# 3) Nihai tablolar\n",
    "# =========================\n",
    "vehicle_daily = pd.concat(vehicle_daily_rows, ignore_index=True)\n",
    "\n",
    "vehicle_daily_final = vehicle_daily.groupby([\"date\", \"vehicle_id\"], as_index=False).agg(\n",
    "    total_dist_km=(\"total_dist_km\", \"sum\"),\n",
    "    total_idle_sec=(\"total_idle_sec\", \"sum\"),\n",
    "    total_stop_sec=(\"total_stop_sec\", \"sum\"),\n",
    "    first_ts=(\"first_ts\", \"min\"),\n",
    "    last_ts=(\"last_ts\", \"max\"),\n",
    "    odo_min=(\"odo_min\", \"min\"),\n",
    "    odo_max=(\"odo_max\", \"max\"),\n",
    "    records=(\"records\", \"sum\")\n",
    ")\n",
    "\n",
    "vehicle_daily_final[\"odo_dist_km\"] = vehicle_daily_final[\"odo_max\"] - vehicle_daily_final[\"odo_min\"]\n",
    "vehicle_daily_final[\"work_duration_sec\"] = (vehicle_daily_final[\"last_ts\"] - vehicle_daily_final[\"first_ts\"]).dt.total_seconds().fillna(0)\n",
    "\n",
    "vehicle_daily_final[\"total_idle_hr\"] = vehicle_daily_final[\"total_idle_sec\"] / 3600\n",
    "vehicle_daily_final[\"total_stop_hr\"] = vehicle_daily_final[\"total_stop_sec\"] / 3600\n",
    "vehicle_daily_final[\"work_duration_hr\"] = vehicle_daily_final[\"work_duration_sec\"] / 3600\n",
    "\n",
    "vehicle_daily_final.to_csv(OUT_VEHICLE, index=False)\n",
    "\n",
    "veh_day_neigh = pd.concat(veh_day_neigh_rows, ignore_index=True)\n",
    "\n",
    "neigh_daily_final = veh_day_neigh.groupby([\"date\", \"Mahalle\"], as_index=False).agg(\n",
    "    total_time_in_neigh_sec=(\"time_in_neigh_sec\", \"sum\"),\n",
    "    total_dist_in_neigh_km=(\"dist_in_neigh_km\", \"sum\"),\n",
    "    total_idle_in_neigh_sec=(\"idle_in_neigh_sec\", \"sum\"),\n",
    "    total_stop_in_neigh_sec=(\"stop_in_neigh_sec\", \"sum\"),\n",
    "    total_points=(\"points\", \"sum\"),\n",
    "    vehicles_served=(\"vehicle_id\", \"nunique\")\n",
    ")\n",
    "\n",
    "neigh_daily_final[\"total_time_in_neigh_hr\"] = neigh_daily_final[\"total_time_in_neigh_sec\"] / 3600\n",
    "neigh_daily_final[\"total_idle_in_neigh_hr\"] = neigh_daily_final[\"total_idle_in_neigh_sec\"] / 3600\n",
    "neigh_daily_final[\"total_stop_in_neigh_hr\"] = neigh_daily_final[\"total_stop_in_neigh_sec\"] / 3600\n",
    "\n",
    "neigh_daily_final.to_csv(OUT_NEIGH, index=False)\n",
    "veh_day_neigh.to_csv(OUT_VEH_NEI, index=False)\n",
    "\n",
    "print(\"Faz 1 tamam.\")\n",
    "print(\"Yazılan dosyalar:\")\n",
    "print(\" -\", OUT_VEHICLE.resolve())\n",
    "print(\" -\", OUT_NEIGH.resolve())\n",
    "print(\" -\", OUT_VEH_NEI.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e55bb-c131-44a6-84be-89a955cfc804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

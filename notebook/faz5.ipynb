{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58e71380-c8ae-402f-a399-c48938a904e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAZ 5 (CONTAINER + TEKİLLEŞTİRME) TAMAMLANDI\n",
      "-> phase5_routes.csv\n",
      "-> phase5_vehicle_summary.csv\n",
      "Tekilleştirme grid: 25m, TOP_K: 80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# =====================================================\n",
    "# 1. YARDIMCI FONKSİYONLAR (AYNI)\n",
    "# =====================================================\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1)*cos(lat2)*sin(dlon/2)**2\n",
    "    return 2 * R * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "def route_distance(route):\n",
    "    return sum(\n",
    "        haversine(\n",
    "            route[i-1][\"lat\"], route[i-1][\"lon\"],\n",
    "            route[i][\"lat\"], route[i][\"lon\"]\n",
    "        )\n",
    "        for i in range(1, len(route))\n",
    "    )\n",
    "\n",
    "def nearest_neighbor(points):\n",
    "    if len(points) <= 1:\n",
    "        return points\n",
    "    unvisited = points.copy()\n",
    "    route = [unvisited.pop(0)]\n",
    "    while unvisited:\n",
    "        last = route[-1]\n",
    "        next_point = min(\n",
    "            unvisited,\n",
    "            key=lambda p: haversine(last[\"lat\"], last[\"lon\"], p[\"lat\"], p[\"lon\"])\n",
    "        )\n",
    "        route.append(next_point)\n",
    "        unvisited.remove(next_point)\n",
    "    return route\n",
    "\n",
    "def two_opt(route):\n",
    "    improved = True\n",
    "    while improved:\n",
    "        improved = False\n",
    "        for i in range(1, len(route) - 2):\n",
    "            for j in range(i + 1, len(route)):\n",
    "                if j - i == 1:\n",
    "                    continue\n",
    "                new_route = route[:i] + route[i:j][::-1] + route[j:]\n",
    "                if route_distance(new_route) < route_distance(route):\n",
    "                    route = new_route\n",
    "                    improved = True\n",
    "    return route\n",
    "\n",
    "# =====================================================\n",
    "# 2. VERİYİ OKU\n",
    "# =====================================================\n",
    "\n",
    "containers = pd.read_csv(\"container_candidates.csv\")\n",
    "\n",
    "# =====================================================\n",
    "# 3. TEMİZLİK (MINIMUM)\n",
    "# =====================================================\n",
    "\n",
    "containers[\"date\"] = pd.to_datetime(containers[\"date\"], errors=\"coerce\").dt.date.astype(str)\n",
    "\n",
    "# numeric lat/lon\n",
    "containers[\"lat\"] = pd.to_numeric(containers[\"lat\"], errors=\"coerce\")\n",
    "containers[\"lon\"] = pd.to_numeric(containers[\"lon\"], errors=\"coerce\")\n",
    "containers = containers.dropna(subset=[\"lat\", \"lon\", \"date\", \"vehicle_id\"])\n",
    "\n",
    "# vehicle_type yoksa koru\n",
    "if \"vehicle_type\" not in containers.columns:\n",
    "    containers[\"vehicle_type\"] = \"UNKNOWN\"\n",
    "\n",
    "# score yoksa türet (yoksa sıralama için 0 basar)\n",
    "if \"score\" not in containers.columns:\n",
    "    containers[\"score\"] = 0.0\n",
    "else:\n",
    "    containers[\"score\"] = pd.to_numeric(containers[\"score\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# duration yoksa 0 yap (tekilleştirmede yedek kriter)\n",
    "if \"duration_min\" not in containers.columns:\n",
    "    containers[\"duration_min\"] = 0.0\n",
    "else:\n",
    "    containers[\"duration_min\"] = pd.to_numeric(containers[\"duration_min\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# =====================================================\n",
    "# 3.1 TOP-K (vehicle-day bazında)\n",
    "# =====================================================\n",
    "\n",
    "TOP_K_PER_VEHICLE_DAY = 80  # istersen 50/100 yap\n",
    "containers = (\n",
    "    containers.sort_values([\"date\", \"vehicle_id\", \"score\", \"duration_min\"],\n",
    "                           ascending=[True, True, False, False])\n",
    "    .groupby([\"date\", \"vehicle_id\"], as_index=False)\n",
    "    .head(TOP_K_PER_VEHICLE_DAY)\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 3.2 YAKIN NOKTALARI TEKİLLEŞTİR (GRID ~ metre)\n",
    "# =====================================================\n",
    "\n",
    "GRID_METERS = 25  # 15-30m genelde iyi. GPS sapması yüksekse 30m yap.\n",
    "\n",
    "def add_grid_id(df: pd.DataFrame, grid_m: float) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    # 1 derece lat ~ 111_320 m\n",
    "    lat_step = grid_m / 111_320.0\n",
    "    # lon adımı enlemle değişir: 1 derece lon ~ 111_320*cos(lat)\n",
    "    lat_rad = np.deg2rad(df[\"lat\"].astype(float))\n",
    "    lon_step = grid_m / (111_320.0 * np.cos(lat_rad).clip(lower=0.2))  # kutup koruması\n",
    "\n",
    "    df[\"grid_lat\"] = np.floor(df[\"lat\"] / lat_step).astype(\"int64\")\n",
    "    df[\"grid_lon\"] = np.floor(df[\"lon\"] / lon_step).astype(\"int64\")\n",
    "\n",
    "    # vehicle-day içinde tekilleştireceğimiz anahtar\n",
    "    df[\"grid_id\"] = df[\"grid_lat\"].astype(str) + \"_\" + df[\"grid_lon\"].astype(str)\n",
    "    return df\n",
    "\n",
    "containers = add_grid_id(containers, GRID_METERS)\n",
    "\n",
    "# Aynı (date, vehicle_id, grid_id) içinde EN iyi kaydı tut:\n",
    "# önce score, sonra duration_min büyük olan kazansın.\n",
    "containers = (\n",
    "    containers.sort_values([\"date\", \"vehicle_id\", \"grid_id\", \"score\", \"duration_min\"],\n",
    "                           ascending=[True, True, True, False, False])\n",
    "    .groupby([\"date\", \"vehicle_id\", \"grid_id\"], as_index=False)\n",
    "    .head(1)\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 4. ROTA OPTİMİZASYONU\n",
    "# =====================================================\n",
    "\n",
    "routes = []\n",
    "vehicle_summary = []\n",
    "\n",
    "for (date, vehicle_id), group in containers.groupby([\"date\", \"vehicle_id\"]):\n",
    "\n",
    "    points = [\n",
    "        {\n",
    "            \"Mahalle\": (r[\"aciklama\"] if \"aciklama\" in group.columns else \"CONTAINER\"),\n",
    "            \"lat\": r[\"lat\"],\n",
    "            \"lon\": r[\"lon\"]\n",
    "        }\n",
    "        for _, r in group.iterrows()\n",
    "    ]\n",
    "\n",
    "    if len(points) == 0:\n",
    "        continue\n",
    "\n",
    "    route = two_opt(nearest_neighbor(points))\n",
    "    total_km = route_distance(route)\n",
    "\n",
    "    prev = None\n",
    "    for idx, stop in enumerate(route):\n",
    "        dist_prev = 0 if prev is None else haversine(\n",
    "            prev[\"lat\"], prev[\"lon\"], stop[\"lat\"], stop[\"lon\"]\n",
    "        )\n",
    "        routes.append({\n",
    "            \"date\": date,\n",
    "            \"vehicle_id\": vehicle_id,\n",
    "            \"vehicle_type\": group[\"vehicle_type\"].iloc[0],\n",
    "            \"stop_order\": idx + 1,\n",
    "            \"Mahalle\": stop[\"Mahalle\"],   # burada \"container açıklaması\" gibi düşün\n",
    "            \"latitude\": stop[\"lat\"],\n",
    "            \"longitude\": stop[\"lon\"],\n",
    "            \"distance_from_prev_km\": round(dist_prev, 3)\n",
    "        })\n",
    "        prev = stop\n",
    "\n",
    "    vehicle_summary.append({\n",
    "        \"date\": date,\n",
    "        \"vehicle_id\": vehicle_id,\n",
    "        \"vehicle_type\": group[\"vehicle_type\"].iloc[0],\n",
    "        \"stops\": len(route),\n",
    "        \"total_distance_km\": round(total_km, 2)\n",
    "    })\n",
    "\n",
    "# =====================================================\n",
    "# 5. KAYDET\n",
    "# =====================================================\n",
    "\n",
    "pd.DataFrame(routes).to_csv(\"phase5_routes.csv\", index=False)\n",
    "pd.DataFrame(vehicle_summary).to_csv(\"phase5_vehicle_summary.csv\", index=False)\n",
    "\n",
    "print(\"✅ FAZ 5 (CONTAINER + TEKİLLEŞTİRME) TAMAMLANDI\")\n",
    "print(\"-> phase5_routes.csv\")\n",
    "print(\"-> phase5_vehicle_summary.csv\")\n",
    "print(f\"Tekilleştirme grid: {GRID_METERS}m, TOP_K: {TOP_K_PER_VEHICLE_DAY}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424f2b24-5181-4263-ab01-a05f5aa5f575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> phase4_assignments_addrfmt.csv\n",
      "Örnek 10 mahalle:\n",
      " Görükle Mh.\n",
      "    Çali Mh.\n",
      " Üçevler Mh.\n",
      " Üçevler Mh.\n",
      " Üçevler Mh.\n",
      " Üçevler Mh.\n",
      "Esentepe Mh.\n",
      "Esentepe Mh.\n",
      "Esentepe Mh.\n",
      "Esentepe Mh.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "IN_FILE  = \"phase4_assignments.csv\"\n",
    "OUT_FILE = \"phase4_assignments_addrfmt.csv\"   # yeni dosya\n",
    "\n",
    "def to_address_format(mahalle: str) -> str:\n",
    "    if pd.isna(mahalle):\n",
    "        return mahalle\n",
    "\n",
    "    m = str(mahalle).strip()\n",
    "\n",
    "    # Tamamı büyükse sorun değil; önce normalize edelim\n",
    "    m_upper = m.upper()\n",
    "\n",
    "    # Sondaki \"MAHALLESİ\" (veya olası varyantlar) kaldır\n",
    "    for suf in [\" MAHALLESİ\", \" MAH.\", \" MAH\", \" MH.\", \" MH\"]:\n",
    "        if m_upper.endswith(suf):\n",
    "            m_upper = m_upper[: -len(suf)].strip()\n",
    "            break\n",
    "\n",
    "    # Title Case (kelimelerin ilk harfi büyük)\n",
    "    m_title = m_upper.title()\n",
    "\n",
    "    # Sonuna \" Mh.\" ekle\n",
    "    return f\"{m_title} Mh.\"\n",
    "\n",
    "# Oku\n",
    "df = pd.read_csv(IN_FILE)\n",
    "\n",
    "# Kolon kontrol\n",
    "if \"Mahalle\" not in df.columns:\n",
    "    raise ValueError(f\"{IN_FILE} içinde 'Mahalle' kolonu yok. Kolonlar: {list(df.columns)}\")\n",
    "\n",
    "# Dönüştür (Mahalle kolonunu direkt overwrite ediyoruz)\n",
    "df[\"Mahalle\"] = df[\"Mahalle\"].apply(to_address_format)\n",
    "\n",
    "# Kaydet\n",
    "df.to_csv(OUT_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"OK ->\", OUT_FILE)\n",
    "print(\"Örnek 10 mahalle:\")\n",
    "print(df[\"Mahalle\"].dropna().head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97b109d3-72e2-4913-8896-9da8a0017795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> address_data_eng.csv kaydedildi\n",
      "OK -> phase4_assignments_eng.csv kaydedildi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Türkçe -> İngilizce karakter dönüşümü\n",
    "# =========================\n",
    "TR_TO_ENG = str.maketrans({\n",
    "    \"ç\": \"c\", \"Ç\": \"C\",\n",
    "    \"ğ\": \"g\", \"Ğ\": \"G\",\n",
    "    \"ı\": \"i\", \"I\": \"I\", \"İ\": \"I\",\n",
    "    \"ö\": \"o\", \"Ö\": \"O\",\n",
    "    \"ş\": \"s\", \"Ş\": \"S\",\n",
    "    \"ü\": \"u\", \"Ü\": \"U\"\n",
    "})\n",
    "\n",
    "def tr_to_eng(s):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    return str(s).translate(TR_TO_ENG)\n",
    "\n",
    "# =========================\n",
    "# 1) address_data.csv -> address_data_eng.csv\n",
    "#    neighborhood kolonu Türkçe karakterlerden arındırılacak\n",
    "# =========================\n",
    "addr = pd.read_csv(\"address_data.csv\", low_memory=False)\n",
    "\n",
    "if \"neighborhood\" not in addr.columns:\n",
    "    raise ValueError(f\"address_data.csv içinde 'neighborhood' kolonu yok. Kolonlar: {list(addr.columns)}\")\n",
    "\n",
    "addr[\"neighborhood\"] = addr[\"neighborhood\"].apply(tr_to_eng)\n",
    "\n",
    "addr.to_csv(\"address_data_eng.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"OK -> address_data_eng.csv kaydedildi\")\n",
    "\n",
    "# =========================\n",
    "# 2) phase4_assignments_addrfmt.csv -> phase4_assignments_eng.csv\n",
    "#    Mahalle kolonu Türkçe karakterlerden arındırılacak\n",
    "# =========================\n",
    "ass = pd.read_csv(\"phase4_assignments_addrfmt.csv\", low_memory=False)\n",
    "\n",
    "if \"Mahalle\" not in ass.columns:\n",
    "    raise ValueError(f\"phase4_assignments_addrfmt.csv içinde 'Mahalle' kolonu yok. Kolonlar: {list(ass.columns)}\")\n",
    "\n",
    "ass[\"Mahalle\"] = ass[\"Mahalle\"].apply(tr_to_eng)\n",
    "\n",
    "ass.to_csv(\"phase4_assignments_eng.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"OK -> phase4_assignments_eng.csv kaydedildi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78fed4bb-9ffd-4909-8bc9-3a6bbe9189db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (phase4) unique canon mahalle: 61\n",
      "B (address, coord ok) unique canon mahalle: 69\n",
      "A'da olup B'de olmayan: 15\n",
      "B'de olup A'da olmayan: 23\n",
      "\n",
      "A'da olup B'de olmayan ilk 30: ['23 ni̇san mh', '30 agustos mh', 'ahmet yesevi̇ mh', 'alaadi̇nbey mh', 'altinsehi̇r mh', 'cumhuri̇yet mh', 'dagyeni̇ce mh', 'demi̇rci̇ mh', 'fethi̇ye mh', 'ihsani̇ye mh', 'inegazi̇ mh', 'irfani̇ye mh', 'kadri̇ye mh', 'maksempinar mh', 'mi̇nareli̇cavus mh']\n",
      "\n",
      "PROBE: cumhuriyet mh\n",
      "Phase4'te var mı?: False\n",
      "Address'te var mı?: True\n",
      "Phase4 'cumhuriyet' adayları: []\n",
      "\n",
      "--- ADDRESS raw neighborhood örneği ---\n",
      "RAW repr : 'Cumhuriyet Mh.'\n",
      "NFKC repr: 'Cumhuriyet Mh.'\n",
      "CODEPOINTS: U+0043(LATIN CAPITAL LETTER C) U+0075(LATIN SMALL LETTER U) U+006D(LATIN SMALL LETTER M) U+0068(LATIN SMALL LETTER H) U+0075(LATIN SMALL LETTER U) U+0072(LATIN SMALL LETTER R) U+0069(LATIN SMALL LETTER I) U+0079(LATIN SMALL LETTER Y) U+0065(LATIN SMALL LETTER E) U+0074(LATIN SMALL LETTER T) U+0020(SPACE) U+004D(LATIN CAPITAL LETTER M) U+0068(LATIN SMALL LETTER H) U+002E(FULL STOP)\n",
      "\n",
      "Öneri dosyası yazıldı: phase5_neighborhood_mapping_suggestions.csv\n",
      "Otomatik map'lenecek (yüksek güven): 12\n",
      "\n",
      "✅ Düzeltilmiş phase4 kaydedildi: phase4_assignments_fixed.csv\n",
      "\n",
      "SONRA NE YAPACAKSIN?\n",
      "- Faz-5 kodunda assignments = pd.read_csv('phase4_assignments_fixed.csv') yap.\n",
      "- Address için zaten 'address_data_eng.csv' kullan.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# =========================\n",
    "# 0) DOSYALAR\n",
    "# =========================\n",
    "A_FILE = \"phase4_assignments_eng.csv\"   # veya phase4_assignments_addrfmt.csv hangisi gerçekse\n",
    "B_FILE = \"address_data_eng.csv\"         # address_data.csv'den ürettiğin ingilizce karakterli dosya\n",
    "\n",
    "A_COL  = \"Mahalle\"\n",
    "B_COL  = \"neighborhood\"\n",
    "\n",
    "OUT_FIXED = \"phase4_assignments_fixed.csv\"\n",
    "OUT_MAP   = \"phase5_neighborhood_mapping_suggestions.csv\"\n",
    "\n",
    "# =========================\n",
    "# 1) KANONİKLEŞTİRME\n",
    "# =========================\n",
    "def canon(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "\n",
    "    # Unicode normalize (farklı \"i/ı\", farklı nokta, NBSP vs yakalamak için)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "\n",
    "    # NBSP ve görünmez boşlukları normal space yap\n",
    "    s = s.replace(\"\\u00A0\", \" \").replace(\"\\u200B\", \"\").replace(\"\\ufeff\", \"\")\n",
    "\n",
    "    # Trim + lower\n",
    "    s = s.strip().lower()\n",
    "\n",
    "    # Birden fazla boşluğu teke indir\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "    # Sonekleri standardize et: \"mahallesi\" / \"mah.\" / \"mh\" / \"mh.\" -> \"mh\"\n",
    "    # (İstersen \"mh.\" istiyorsan en sonda tekrar nokta ekleyebiliriz)\n",
    "    s = re.sub(r\"\\bmahallesi\\b\", \"mh\", s)\n",
    "    s = re.sub(r\"\\bmah\\.\\b\", \"mh\", s)\n",
    "    s = re.sub(r\"\\bmah\\b\", \"mh\", s)\n",
    "    s = re.sub(r\"\\bmh\\.\\b\", \"mh\", s)\n",
    "    s = re.sub(r\"\\bmh\\b\", \"mh\", s)\n",
    "\n",
    "    # Noktalama işaretlerini temizle (sonradan istersek geri ekleriz)\n",
    "    s = re.sub(r\"[.\\-_/']\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "    return s\n",
    "\n",
    "def show_unicode_debug(label, s, max_chars=120):\n",
    "    s = \"\" if pd.isna(s) else str(s)\n",
    "    sn = unicodedata.normalize(\"NFKC\", s)\n",
    "    print(f\"\\n--- {label} ---\")\n",
    "    print(\"RAW repr :\", repr(s[:max_chars]))\n",
    "    print(\"NFKC repr:\", repr(sn[:max_chars]))\n",
    "    # ilk 80 karakterin codepointlerini göster\n",
    "    cps = []\n",
    "    for ch in sn[:80]:\n",
    "        cps.append(f\"U+{ord(ch):04X}({unicodedata.name(ch, 'UNKNOWN')})\")\n",
    "    print(\"CODEPOINTS:\", \" \".join(cps))\n",
    "\n",
    "# =========================\n",
    "# 2) OKU\n",
    "# =========================\n",
    "a = pd.read_csv(A_FILE, low_memory=False)\n",
    "b = pd.read_csv(B_FILE, low_memory=False)\n",
    "\n",
    "if A_COL not in a.columns:\n",
    "    raise ValueError(f\"{A_FILE} içinde '{A_COL}' kolonu yok. Kolonlar: {list(a.columns)}\")\n",
    "if B_COL not in b.columns:\n",
    "    raise ValueError(f\"{B_FILE} içinde '{B_COL}' kolonu yok. Kolonlar: {list(b.columns)}\")\n",
    "\n",
    "a[\"k\"] = a[A_COL].apply(canon)\n",
    "b[\"k\"] = b[B_COL].apply(canon)\n",
    "\n",
    "# Address tarafında koordinatlar (senin sistemin için)\n",
    "# Eğer street_latitude/street_longitude yoksa burayı kendi kolonlarına göre düzelt.\n",
    "LAT_COL = \"street_latitude\"\n",
    "LON_COL = \"street_longitude\"\n",
    "for c in [LAT_COL, LON_COL]:\n",
    "    if c not in b.columns:\n",
    "        raise ValueError(f\"{B_FILE} içinde '{c}' kolonu yok. Kolonlar: {list(b.columns)}\")\n",
    "\n",
    "b[LAT_COL] = pd.to_numeric(b[LAT_COL], errors=\"coerce\")\n",
    "b[LON_COL] = pd.to_numeric(b[LON_COL], errors=\"coerce\")\n",
    "b_ok = b.dropna(subset=[LAT_COL, LON_COL]).copy()\n",
    "\n",
    "# =========================\n",
    "# 3) BİREBİR EŞLEŞME KONTROLÜ\n",
    "# =========================\n",
    "set_a = set(a[\"k\"].dropna().unique())\n",
    "set_b = set(b_ok[\"k\"].dropna().unique())\n",
    "\n",
    "only_in_a = sorted(set_a - set_b)\n",
    "only_in_b = sorted(set_b - set_a)\n",
    "\n",
    "print(\"A (phase4) unique canon mahalle:\", len(set_a))\n",
    "print(\"B (address, coord ok) unique canon mahalle:\", len(set_b))\n",
    "print(\"A'da olup B'de olmayan:\", len(only_in_a))\n",
    "print(\"B'de olup A'da olmayan:\", len(only_in_b))\n",
    "\n",
    "print(\"\\nA'da olup B'de olmayan ilk 30:\", only_in_a[:30])\n",
    "\n",
    "# =========================\n",
    "# 4) ŞÜPHELİ ÖRNEKLERDE GİZLİ KARAKTER ANALİZİ\n",
    "#    (Senin örneğin: \"cumhuriyet mh\" gibi)\n",
    "# =========================\n",
    "probe = \"cumhuriyet mh\"\n",
    "print(\"\\nPROBE:\", probe)\n",
    "print(\"Phase4'te var mı?:\", probe in set_a)\n",
    "print(\"Address'te var mı?:\", probe in set_b)\n",
    "\n",
    "if probe not in set_a:\n",
    "    # Phase4 tarafında 'cumhuriyet' içeren adayları göster\n",
    "    cand_a = sorted([x for x in set_a if \"cumhuriyet\" in x])\n",
    "    print(\"Phase4 'cumhuriyet' adayları:\", cand_a[:20])\n",
    "if probe in set_b:\n",
    "    # Address'ten orijinal örneği bulup unicode debug yap\n",
    "    raw_b = b_ok.loc[b_ok[\"k\"] == probe, B_COL].iloc[0]\n",
    "    show_unicode_debug(\"ADDRESS raw neighborhood örneği\", raw_b)\n",
    "\n",
    "# Eğer Phase4’te görünürde var diyorsan, Phase4’ten de yakalayıp debug edelim:\n",
    "raw_a_rows = a.loc[a[\"k\"].str.contains(\"cumhuriyet\", na=False), A_COL].head(3).tolist()\n",
    "if raw_a_rows:\n",
    "    show_unicode_debug(\"PHASE4 raw Mahalle örneği\", raw_a_rows[0])\n",
    "\n",
    "# =========================\n",
    "# 5) EŞLEŞMEYENLER İÇİN FUZZY ÖNERİ (KANONİK ÜZERİNDEN)\n",
    "# =========================\n",
    "# Not: difflib hızlı ve kurulu geliyor. RapidFuzz varsa daha iyi ama şart değil.\n",
    "b_keys = sorted(set_b)\n",
    "\n",
    "suggestions = []\n",
    "for k in only_in_a:\n",
    "    # en yakın 3 adayı öner\n",
    "    close = get_close_matches(k, b_keys, n=3, cutoff=0.85)\n",
    "    suggestions.append({\n",
    "        \"phase4_key\": k,\n",
    "        \"suggested_address_keys\": \" | \".join(close) if close else \"\"\n",
    "    })\n",
    "\n",
    "map_df = pd.DataFrame(suggestions)\n",
    "map_df.to_csv(OUT_MAP, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nÖneri dosyası yazıldı: {OUT_MAP}\")\n",
    "\n",
    "# =========================\n",
    "# 6) OTOMATİK DÜZELTME (SADECE %100 EMİN OLDUKLARINI UYGULA)\n",
    "# =========================\n",
    "# Burada otomatik uygulama için cutoff'u yüksek tutuyoruz.\n",
    "auto_map = {}\n",
    "for row in suggestions:\n",
    "    k = row[\"phase4_key\"]\n",
    "    close = get_close_matches(k, b_keys, n=1, cutoff=0.92)\n",
    "    if close:\n",
    "        auto_map[k] = close[0]\n",
    "\n",
    "print(\"Otomatik map'lenecek (yüksek güven):\", len(auto_map))\n",
    "\n",
    "# Phase4’te canon key'i bu mapping ile güncelle\n",
    "a[\"k_fixed\"] = a[\"k\"].map(lambda x: auto_map.get(x, x))\n",
    "\n",
    "# İstersen Phase4’ün görünen Mahalle yazısını da address formatına yaklaştıralım:\n",
    "# Address'teki bir temsil değerini çekip yazalım (aynı key için en sık görünen)\n",
    "rep = (\n",
    "    b_ok.groupby(\"k\")[B_COL]\n",
    "    .agg(lambda s: s.value_counts().index[0])\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Eğer mapping sonrası k_fixed address tarafında varsa Mahalle'yi address temsil değeriyle değiştir\n",
    "a[A_COL] = a[\"k_fixed\"].map(lambda k: rep.get(k, None)).combine_first(a[A_COL])\n",
    "\n",
    "# Kayıt\n",
    "a.drop(columns=[\"k\", \"k_fixed\"], inplace=True)\n",
    "a.to_csv(OUT_FIXED, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n✅ Düzeltilmiş phase4 kaydedildi: {OUT_FIXED}\")\n",
    "\n",
    "print(\"\\nSONRA NE YAPACAKSIN?\")\n",
    "print(f\"- Faz-5 kodunda assignments = pd.read_csv('{OUT_FIXED}') yap.\")\n",
    "print(f\"- Address için zaten '{B_FILE}' kullan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7a9e5-7d2b-4762-afa2-90e18e168c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
